{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1VoVVImuLgMElIbGFOtIOPfntNH26-Ttv","timestamp":1725038312582}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"041641b3056b4c8e8e24b1206c605b6b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a42fddeccb484de9b8063199a589cb84","IPY_MODEL_6939698e091145dba05252ec182999c3","IPY_MODEL_83aa3d865d984d64a34fe3cd148bff97"],"layout":"IPY_MODEL_52116dbb0af34c8eb24553a42ae229ae"}},"a42fddeccb484de9b8063199a589cb84":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea10f13239f64fa8a09e0c1e395e1b54","placeholder":"​","style":"IPY_MODEL_872660e265af4d74a8940fbf55e1f504","value":"config.json: 100%"}},"6939698e091145dba05252ec182999c3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1e51ae3246d456f95d8887929e0010e","max":385,"min":0,"orientation":"horizontal","style":"IPY_MODEL_605a1a30229c42aba2316e8a4be796a8","value":385}},"83aa3d865d984d64a34fe3cd148bff97":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbd4d48420a0417eb12465e114005526","placeholder":"​","style":"IPY_MODEL_ed0ba9d3dfb543f0ae7d8d068b593a08","value":" 385/385 [00:00&lt;00:00, 27.3kB/s]"}},"52116dbb0af34c8eb24553a42ae229ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea10f13239f64fa8a09e0c1e395e1b54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"872660e265af4d74a8940fbf55e1f504":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1e51ae3246d456f95d8887929e0010e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"605a1a30229c42aba2316e8a4be796a8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dbd4d48420a0417eb12465e114005526":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed0ba9d3dfb543f0ae7d8d068b593a08":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9edb1a409bd4801bb97f74000230347":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b9e5e3cde56e450b843bf253e6be53e8","IPY_MODEL_610f64c7b29d4006b3018c2c83666ad6","IPY_MODEL_d9665730034a4cddb7107708826a708e"],"layout":"IPY_MODEL_715d323cefd24cde922a90cc7e29fa29"}},"b9e5e3cde56e450b843bf253e6be53e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b9ebe0ec6ca49fda52e5baff074353f","placeholder":"​","style":"IPY_MODEL_616cea02635a4fcea7bd688a54d22fd9","value":"vocab.txt: 100%"}},"610f64c7b29d4006b3018c2c83666ad6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e319bda295242559e45c6b75c689180","max":227845,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c5a9693c0ab94682a7e4d2f080514718","value":227845}},"d9665730034a4cddb7107708826a708e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c43d18fb00e4a59945ed094cb1cee6e","placeholder":"​","style":"IPY_MODEL_4b3a2cbea5994b34a2c43815103af575","value":" 228k/228k [00:00&lt;00:00, 6.90MB/s]"}},"715d323cefd24cde922a90cc7e29fa29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b9ebe0ec6ca49fda52e5baff074353f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"616cea02635a4fcea7bd688a54d22fd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e319bda295242559e45c6b75c689180":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5a9693c0ab94682a7e4d2f080514718":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2c43d18fb00e4a59945ed094cb1cee6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b3a2cbea5994b34a2c43815103af575":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"27ca58fa295743aeb286f371015a3247":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_674b8abae8e2492fb6fe9845bebd0350","IPY_MODEL_bf54c24790574624bce6c66c97378541","IPY_MODEL_76cc9314ce474b87be52aec16f166802"],"layout":"IPY_MODEL_8af045db4a5f44f6b963d75a92536aa3"}},"674b8abae8e2492fb6fe9845bebd0350":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_31c3a43b680f449cbd9286d9f60108e7","placeholder":"​","style":"IPY_MODEL_cc84ebe388b4471f9e8c533d8fdd0204","value":"pytorch_model.bin: 100%"}},"bf54c24790574624bce6c66c97378541":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b31c056661c146508116d90732c25e6b","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dde3a729717d4b679452ea0181f35182","value":442221694}},"76cc9314ce474b87be52aec16f166802":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b62b754a54224c31a973f55ae1749ef4","placeholder":"​","style":"IPY_MODEL_1326338297ba4a75bed7d5854da90748","value":" 442M/442M [00:03&lt;00:00, 121MB/s]"}},"8af045db4a5f44f6b963d75a92536aa3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31c3a43b680f449cbd9286d9f60108e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc84ebe388b4471f9e8c533d8fdd0204":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b31c056661c146508116d90732c25e6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dde3a729717d4b679452ea0181f35182":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b62b754a54224c31a973f55ae1749ef4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1326338297ba4a75bed7d5854da90748":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"dOKLn1DkMivt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725035232963,"user_tz":-420,"elapsed":27659,"user":{"displayName":"Thư Minh","userId":"14144658735324852801"}},"outputId":"17b6a8ce-f7ae-43b3-9446-b5766c0d50fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","import transformers\n","from torch.utils.data import Dataset, DataLoader\n","from torch import cuda\n","import sys\n","from sklearn.metrics import f1_score\n","from transformers import AutoTokenizer, AutoModel\n"],"metadata":{"id":"ZOvOVaJqGp1j","executionInfo":{"status":"ok","timestamp":1725035242185,"user_tz":-420,"elapsed":9229,"user":{"displayName":"Thư Minh","userId":"14144658735324852801"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["model_name = 'allenai/scibert_scivocab_uncased'"],"metadata":{"id":"xx2qMmi0Moi2","executionInfo":{"status":"ok","timestamp":1725035242186,"user_tz":-420,"elapsed":5,"user":{"displayName":"Thư Minh","userId":"14144658735324852801"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["\n","LMTokenizer = AutoTokenizer.from_pretrained(model_name)\n","LMModel = AutoModel.from_pretrained(model_name)\n","\n","device = 'cuda' if cuda.is_available() else 'cpu'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":242,"referenced_widgets":["041641b3056b4c8e8e24b1206c605b6b","a42fddeccb484de9b8063199a589cb84","6939698e091145dba05252ec182999c3","83aa3d865d984d64a34fe3cd148bff97","52116dbb0af34c8eb24553a42ae229ae","ea10f13239f64fa8a09e0c1e395e1b54","872660e265af4d74a8940fbf55e1f504","b1e51ae3246d456f95d8887929e0010e","605a1a30229c42aba2316e8a4be796a8","dbd4d48420a0417eb12465e114005526","ed0ba9d3dfb543f0ae7d8d068b593a08","f9edb1a409bd4801bb97f74000230347","b9e5e3cde56e450b843bf253e6be53e8","610f64c7b29d4006b3018c2c83666ad6","d9665730034a4cddb7107708826a708e","715d323cefd24cde922a90cc7e29fa29","1b9ebe0ec6ca49fda52e5baff074353f","616cea02635a4fcea7bd688a54d22fd9","2e319bda295242559e45c6b75c689180","c5a9693c0ab94682a7e4d2f080514718","2c43d18fb00e4a59945ed094cb1cee6e","4b3a2cbea5994b34a2c43815103af575","27ca58fa295743aeb286f371015a3247","674b8abae8e2492fb6fe9845bebd0350","bf54c24790574624bce6c66c97378541","76cc9314ce474b87be52aec16f166802","8af045db4a5f44f6b963d75a92536aa3","31c3a43b680f449cbd9286d9f60108e7","cc84ebe388b4471f9e8c533d8fdd0204","b31c056661c146508116d90732c25e6b","dde3a729717d4b679452ea0181f35182","b62b754a54224c31a973f55ae1749ef4","1326338297ba4a75bed7d5854da90748"]},"id":"6unxFVqtM1nB","executionInfo":{"status":"ok","timestamp":1725035254450,"user_tz":-420,"elapsed":12268,"user":{"displayName":"Thư Minh","userId":"14144658735324852801"}},"outputId":"1e2c04fd-1e55-44e1-cca6-a042809e1bae"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"041641b3056b4c8e8e24b1206c605b6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/228k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9edb1a409bd4801bb97f74000230347"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/442M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27ca58fa295743aeb286f371015a3247"}},"metadata":{}}]},{"cell_type":"code","source":["train_dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/3c-citation_text_classification/task1/third/train.csv', sep=',', names=['CGT','CDT','CC','label'])\n","testing_dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/3c-citation_text_classification/task1/third/validation.csv', sep=',', names=['CGT','CDT','CC','label'])\n","\n","MAX_LEN = 512\n","TRAIN_BATCH_SIZE = 4\n","VALID_BATCH_SIZE = 4\n","LEARNING_RATE = 0.00001\n","drop_out = 0.1\n","EPOCHS = 10\n","tokenizer = LMTokenizer"],"metadata":{"id":"HRz1NHeNM5qr","executionInfo":{"status":"ok","timestamp":1725035290549,"user_tz":-420,"elapsed":1580,"user":{"displayName":"Thư Minh","userId":"14144658735324852801"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["output_file_name = f\"{sys.argv[5]}_{model_name.split('/')[-1]}_{TRAIN_BATCH_SIZE}_{LEARNING_RATE}_{drop_out}.txt\" if len(sys.argv) > 5 else \"output.txt\"\n","file = open(output_file_name,'w')"],"metadata":{"id":"V1_50ryLNKGS","executionInfo":{"status":"ok","timestamp":1725035299088,"user_tz":-420,"elapsed":565,"user":{"displayName":"Thư Minh","userId":"14144658735324852801"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["\n","class Triage(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __getitem__(self, index):\n","        CGT = str(self.data.CGT[index])\n","        CGT = \" \".join(CGT.split())\n","        inputs = self.tokenizer.encode_plus(\n","            CGT,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True,\n","            truncation=True\n","        )\n","        CGT_ids = inputs['input_ids']\n","        CGT_mask = inputs['attention_mask']\n","\n","\n","        CDT = str(self.data.CDT[index])\n","        CDT = \" \".join(CDT.split())\n","        inputs = self.tokenizer.encode_plus(\n","            CDT,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True,\n","            truncation=True\n","        )\n","        CDT_ids = inputs['input_ids']\n","        CDT_mask = inputs['attention_mask']\n","\n","\n","        CC = str(self.data.CC[index])\n","        CC = \" \".join(CC.split())\n","        inputs = self.tokenizer.encode_plus(\n","            CC,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True,\n","            truncation=True\n","        )\n","        CC_ids = inputs['input_ids']\n","        CC_mask = inputs['attention_mask']\n","\n","        return {\n","            'CGT_ids': torch.tensor(CGT_ids, dtype=torch.long),\n","            'CGT_mask': torch.tensor(CGT_mask, dtype=torch.long),\n","\n","            'CDT_ids': torch.tensor(CDT_ids, dtype=torch.long),\n","            'CDT_mask': torch.tensor(CDT_mask, dtype=torch.long),\n","\n","            'CC_ids': torch.tensor(CC_ids, dtype=torch.long),\n","            'CC_mask': torch.tensor(CC_mask, dtype=torch.long),\n","\n","            'targets': torch.tensor(self.data.label[index], dtype=torch.long)\n","        }\n","\n","    def __len__(self):\n","        return self.len\n"],"metadata":{"id":"IvuCPCeZNFHd","executionInfo":{"status":"ok","timestamp":1725035303125,"user_tz":-420,"elapsed":709,"user":{"displayName":"Thư Minh","userId":"14144658735324852801"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["\n","training_set = Triage(train_dataset, tokenizer, MAX_LEN)\n","testing_set = Triage(testing_dataset, tokenizer, MAX_LEN)\n","\n","train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","test_params = {'batch_size': VALID_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","training_loader = DataLoader(training_set, **train_params)\n","testing_loader = DataLoader(testing_set, **test_params)"],"metadata":{"id":"OAMwEth7NTon","executionInfo":{"status":"ok","timestamp":1725035306421,"user_tz":-420,"elapsed":714,"user":{"displayName":"Thư Minh","userId":"14144658735324852801"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["\n","class LMClass(torch.nn.Module):\n","    def __init__(self):\n","        super(LMClass, self).__init__()\n","        self.l1 = LMModel\n","        self.pre_classifier = torch.nn.Linear(768, 768)\n","        self.dropout = torch.nn.Dropout(drop_out)\n","        self.classifier = torch.nn.Linear(768, 6)\n","\n","    def forward(self, data):\n","\n","        input_ids = data['CC_ids'].to(device, dtype = torch.long)\n","        attention_mask = data['CC_mask'].to(device, dtype = torch.long)\n","\n","        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n","        hidden_state1 = output_1[0]\n","\n","        pooler = hidden_state1[:, 0]\n","        pooler = self.pre_classifier(pooler)\n","        pooler = torch.nn.ReLU()(pooler)\n","        pooler = self.dropout(pooler)\n","        output = self.classifier(pooler)\n","        return output"],"metadata":{"id":"MbRp_47yNVG8","executionInfo":{"status":"ok","timestamp":1725035307659,"user_tz":-420,"elapsed":567,"user":{"displayName":"Thư Minh","userId":"14144658735324852801"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["\n","model = LMClass()\n","model.to(device)\n","loss_function = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n"],"metadata":{"id":"abEew35tNYoj","executionInfo":{"status":"ok","timestamp":1725035310327,"user_tz":-420,"elapsed":576,"user":{"displayName":"Thư Minh","userId":"14144658735324852801"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["\n","def calcuate_accu(big_idx, targets):\n","    n_correct = (big_idx==targets).sum().item()\n","    return n_correct\n","\n","\n","def train(epoch):\n","    tr_loss = 0\n","    n_correct = 0\n","    nb_tr_steps = 0\n","    nb_tr_examples = 0\n","    model.train()\n","    for _,data in enumerate(training_loader, 0):\n","        targets = data['targets'].to(device, dtype = torch.long)\n","\n","        outputs = model(data)\n","        # print(outputs.shape)\n","        # print(targets.shape)\n","        loss = loss_function(outputs, targets)\n","        tr_loss += loss.item()\n","        big_val, big_idx = torch.max(outputs.data, dim=1)\n","        n_correct += calcuate_accu(big_idx, targets)\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples+=targets.size(0)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    file.write(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}\\n')\n","    epoch_loss = tr_loss/nb_tr_steps\n","    epoch_accu = (n_correct*100)/nb_tr_examples\n","    file.write(f\"Training Loss Epoch: {epoch_loss}\\n\")\n","    file.write(f\"Training Accuracy Epoch: {epoch_accu}\\n\")\n","    file.write(\"\\n\")\n","    return"],"metadata":{"id":"3jKrM-H8NcGF","executionInfo":{"status":"ok","timestamp":1725035313101,"user_tz":-420,"elapsed":2,"user":{"displayName":"Thư Minh","userId":"14144658735324852801"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def valid(model, testing_loader):\n","    model.eval()\n","    n_correct = 0; n_wrong = 0; tr_loss = 0\n","    nb_tr_steps =0\n","    nb_tr_examples =0\n","    pred = []\n","    act = []\n","    with torch.no_grad():\n","        for _, data in enumerate(testing_loader, 0):\n","            targets = data['targets'].to(device, dtype = torch.long)\n","            outputs = model(data).squeeze()\n","            loss = loss_function(outputs, targets)\n","            tr_loss += loss.item()\n","            big_val, big_idx = torch.max(outputs.data, dim=1)\n","            n_correct += calcuate_accu(big_idx, targets)\n","            pred += big_idx.tolist()\n","            act += targets.tolist()\n","            nb_tr_steps += 1\n","            nb_tr_examples+=targets.size(0)\n","\n","    epoch_loss = tr_loss/nb_tr_steps\n","    epoch_accu = (n_correct*100)/nb_tr_examples\n","    file.write(f\"Validation Loss Epoch: {epoch_loss}\\n\")\n","    file.write(f\"Validation Accuracy Epoch: {epoch_accu}\\n\")\n","    mf1 = f1_score(act, pred, average='macro')\n","    file.write(f\"Validation Macro F1: {mf1}\\n\")\n","    return mf1,epoch_accu"],"metadata":{"id":"GqGmLkBQNfP2","executionInfo":{"status":"ok","timestamp":1725035632548,"user_tz":-420,"elapsed":637,"user":{"displayName":"Thư Minh","userId":"14144658735324852801"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["best_model_path = '/content/drive/MyDrive/best_model.pt'"],"metadata":{"id":"05e3CcXPIH5k","executionInfo":{"status":"ok","timestamp":1725035635035,"user_tz":-420,"elapsed":590,"user":{"displayName":"Thư Minh","userId":"14144658735324852801"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["class EarlyStopping:\n","    def __init__(self, patience=5, verbose=False):\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.best_acc = 0\n","        self.best_epoch = 0\n","\n","    def __call__(self, epoch_acc, model, epoch):\n","        score = epoch_acc\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(model)\n","        elif score <= self.best_score:\n","            self.counter += 1\n","            if self.verbose:\n","                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(model)\n","            self.counter = 0\n","            self.best_acc = score\n","            self.best_epoch = epoch + 1\n","\n","    def save_checkpoint(self, model):\n","        torch.save(model.state_dict(), best_model_path)\n"],"metadata":{"id":"Un7zBifjD465","executionInfo":{"status":"ok","timestamp":1725035637275,"user_tz":-420,"elapsed":616,"user":{"displayName":"Thư Minh","userId":"14144658735324852801"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Instantiate the EarlyStopping object\n","early_stopping = EarlyStopping(patience=5, verbose=True)\n","\n","best_mf1 = 0\n","\n","for epoch in range(EPOCHS):\n","    train(epoch)\n","    mf1, acc = valid(model, testing_loader)\n","    if mf1 > best_mf1:\n","        best_mf1 = mf1\n","\n","    early_stopping(acc, model, epoch)\n","\n","    if early_stopping.early_stop:\n","        print(f\"Early stopping at epoch {epoch+1}\")\n","        break\n","\n","file.write(\"Best \\nAccuracy: {0} \\nMacro F1 Score: {1}\\nAt Epoch: {2}\\n\".format(early_stopping.best_acc, best_mf1, early_stopping.best_epoch))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6AR3GDzuNmAg","executionInfo":{"status":"ok","timestamp":1725037537710,"user_tz":-420,"elapsed":1897834,"user":{"displayName":"Thư Minh","userId":"14144658735324852801"}},"outputId":"a32f33f9-d50e-4489-b97f-ed8b35929004"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["EarlyStopping counter: 1 out of 5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["EarlyStopping counter: 2 out of 5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["EarlyStopping counter: 3 out of 5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["EarlyStopping counter: 4 out of 5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["EarlyStopping counter: 5 out of 5\n","Early stopping at epoch 7\n"]},{"output_type":"execute_result","data":{"text/plain":["70"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["file.close()"],"metadata":{"id":"Cq9Xl_ytR1j_","executionInfo":{"status":"ok","timestamp":1725038038434,"user_tz":-420,"elapsed":1577,"user":{"displayName":"Thư Minh","userId":"14144658735324852801"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# Tải lại model tốt nhất để sử dụng sau này (nếu cần)\n","model.load_state_dict(torch.load(best_model_path))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MwpzdHA4H6Sx","executionInfo":{"status":"ok","timestamp":1725037538513,"user_tz":-420,"elapsed":814,"user":{"displayName":"Thư Minh","userId":"14144658735324852801"}},"outputId":"5e0f0389-4423-47e0-bebc-260df8a8d19c"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-16-a3d97d0d943c>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(best_model_path))\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["**Predict**"],"metadata":{"id":"VeIsROTSJBRK"}},{"cell_type":"code","source":["import torch\n","import nltk\n","from nltk.tokenize import sent_tokenize\n","\n","# Ensure you have NLTK tokenizer downloaded\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9nV7y90HK8gI","executionInfo":{"status":"ok","timestamp":1725037541461,"user_tz":-420,"elapsed":834,"user":{"displayName":"Thư Minh","userId":"14144658735324852801"}},"outputId":"b1eeb451-1770-4b85-bcaa-971dd3b4d328"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["class LMClassPredictor:\n","    def __init__(self, model_path, tokenizer, device='cpu'):\n","        self.device = device\n","        self.model = LMClass()\n","        self.model.load_state_dict(torch.load(model_path, map_location=device))\n","        self.model.to(device)\n","        self.model.eval()\n","        self.tokenizer = tokenizer\n","\n","    def predict_sentence(self, sentence):\n","        inputs = self.tokenizer.encode_plus(\n","            sentence,\n","            None,\n","            add_special_tokens=True,\n","            max_length=512,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True,\n","            truncation=True\n","        )\n","        input_ids = torch.tensor(inputs['input_ids'], dtype=torch.long).unsqueeze(0).to(self.device)\n","        attention_mask = torch.tensor(inputs['attention_mask'], dtype=torch.long).unsqueeze(0).to(self.device)\n","\n","        with torch.no_grad():\n","            data = {\n","                'CC_ids': input_ids,\n","                'CC_mask': attention_mask\n","            }\n","            outputs = self.model(data)\n","            probabilities = torch.softmax(outputs, dim=1)\n","            predicted_label = torch.argmax(probabilities, dim=1).item()\n","\n","        return predicted_label, probabilities\n","\n","    def predict_paragraph(self, paragraph, output_file):\n","        sentences = sent_tokenize(paragraph)\n","        results = []\n","\n","        with open(output_file, 'w') as file:\n","            for sentence in sentences:\n","                predicted_label, probabilities = self.predict_sentence(sentence)\n","                results.append((sentence, predicted_label, probabilities))\n","                file.write(f\"Sentence: {sentence}\\n\")\n","                file.write(f\"Predicted label: {predicted_label}, Probabilities: {probabilities}\\n\")\n","                file.write(\"\\n\")\n","\n","        return results"],"metadata":{"id":"M2T2LcF4JC4m","executionInfo":{"status":"ok","timestamp":1725037541461,"user_tz":-420,"elapsed":5,"user":{"displayName":"Thư Minh","userId":"14144658735324852801"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["predictor = LMClassPredictor(model_path= best_model_path, tokenizer=LMTokenizer, device=device)\n","paragraph = \"This is the first sentence. Here is another one.\"\n","results = predictor.predict_paragraph(paragraph, output_file='/content/drive/MyDrive/predictions.txt')\n","print(\"Predictions saved to predictions.txt\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gshsd6OcKAR8","executionInfo":{"status":"ok","timestamp":1725037542872,"user_tz":-420,"elapsed":1415,"user":{"displayName":"Thư Minh","userId":"14144658735324852801"}},"outputId":"afd25929-c7aa-4b76-df68-0bbb172a3fcd"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-18-4360c6949b4c>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  self.model.load_state_dict(torch.load(model_path, map_location=device))\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Predictions saved to predictions.txt\n"]}]}]}